{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Importing necessary libraries\n",
    "from datasets import load_dataset\n",
    "import unicodedata as ud\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "import string\n",
    "import pandas as pd\n",
    "import json\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "# Stopwords tiếng Việt\n",
    "stop_words_vn = set([\n",
    "    \"của\", \"và\", \"về\", \"trong\", \"được\", \"là\", \"các\", \"bởi\", \"để\", \"này\",\n",
    "    \"theo\", \"một\", \"hoặc\", \"với\", \"tại\", \"khi\", \"thì\", \"nếu\", \"mà\", \"đã\",\n",
    "    \"những\", \"có\", \"không\", \"trên\", \"dưới\", \"ra\", \"vẫn\", \"lại\", \"rất\",\n",
    "    \"cũng\", \"như\", \"bằng\", \"từ\", \"sẽ\", \"phải\", \"giữa\", \"qua\", \"từng\", \n",
    "    \"thông\", \"báo\", \"căn\", \"cứ\", \"này\", \"phạm\", \"vi\", \"chung\", \"áp\",\n",
    "    \"dụng\", \"chỉ\", \"thứ\", \"trách\", \"nhiệm\", \"hữu\", \"hạn\", \"công\", \"ty\",\n",
    "    \"cổ\", \"phần\", \"hợp\", \"doanh\", \"nghiệp\", \"tư\", \"nhân\", \"bao\", \"gồm\",\n",
    "    \"gọi\", \"tên\", \"sau\", \"cơ\", \"quan\", \"tổ\", \"chức\", \"hoạt\", \"động\",\n",
    "    \"liên\", \"quan\", \"thành\", \"lập\", \"lại\", \"giải\", \"thể\", \"quy\", \"định\",\n",
    "    \"quyền\", \"nghĩa\", \"vụ\", \"bản\", \"sao\", \"giấy\", \"tờ\", \"sổ\", \"chính\",\n",
    "    \"thẩm\", \"đối\", \"chiếu\", \"cá\", \"nhân\", \"nước\", \"ngoài\", \"mang\",\n",
    "    \"người\", \"nhà\", \"địa\", \"số\", \"luật\", \"pháp\", \"việc\", \"điều\", \"khoản\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Loading the dataset\n",
    "meta_corpus = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/Users/nhotin/Documents/GitHub/LegalBizAI_project/test_set/id_cof/chunk_sz_fl_point/all_chunk_final.json\",\n",
    "    split=\"train\"\n",
    ").to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Function to split text\n",
    "def split_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.lower().split()\n",
    "    words = [word for word in words if len(word.strip()) > 0]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Function to retrieve relevant chunks using BM25\n",
    "def retrieve(question, topk=50):\n",
    "    tokenized_query = split_text(question)\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    corpus_size = len(meta_corpus)\n",
    "    for i in range(corpus_size):\n",
    "        meta_corpus[i][\"bm25_score\"] = bm25_scores[i]\n",
    "    bm25_passages = sorted(meta_corpus, key=lambda x: x[\"bm25_score\"], reverse=True)\n",
    "    return bm25_passages[:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4162/4162 [00:00<00:00, 33173.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Initiate BM25 retriever with parameter tuning\n",
    "tokenized_corpus = [split_text(doc[\"passage\"]) for doc in tqdm(meta_corpus)]\n",
    "bm25 = BM25Okapi(tokenized_corpus, k1=2.0, b=0.75)  # Adjust parameters k1 and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Function to get the top similar chunks\n",
    "def getTopSimi(top_retrive):\n",
    "    ids = []\n",
    "    best_retrive = []\n",
    "    score = []\n",
    "    for each in top_retrive:\n",
    "        score.append(each[\"bm25_score\"])\n",
    "    avg_score = sum(score)/len(score)\n",
    "    for each in top_retrive:\n",
    "        if each[\"bm25_score\"] > avg_score:\n",
    "            best_retrive.append(each)\n",
    "            ids.append(each[\"id\"])\n",
    "    ret = dict()\n",
    "    ret[\"copus\"] = best_retrive\n",
    "    ret[\"ids\"] = ids\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Function to get the full article passage\n",
    "def get_full_article(chunks: list[dict], chunk_ids: list[int]) -> dict:\n",
    "    articles_ids = set()\n",
    "    for chunk_id in chunk_ids:\n",
    "        if chunk_id in articles_ids:\n",
    "            continue\n",
    "        articles_ids.add(chunk_id)\n",
    "        chunk_title = chunks[chunk_id][\"title\"]\n",
    "        run_id = chunk_id - 1\n",
    "        while run_id >= 0 and chunks[run_id][\"title\"] == chunk_title:\n",
    "            articles_ids.add(run_id)\n",
    "            run_id -= 1\n",
    "        run_id = chunk_id + 1\n",
    "        while run_id < len(chunks) and chunks[run_id][\"title\"] == chunk_title:\n",
    "            articles_ids.add(run_id)\n",
    "            run_id += 1\n",
    "    articles_ids = sorted(articles_ids)\n",
    "    content_lines = []\n",
    "    chunk_title = \"\"\n",
    "    for id in articles_ids:\n",
    "        if chunk_title != chunks[id][\"title\"]:\n",
    "            chunk_title = chunks[id][\"title\"]\n",
    "            content_lines.append(chunk_title)\n",
    "        passage_lines = chunks[id][\"passage\"].splitlines()\n",
    "        content_lines.extend(passage_lines[1:])\n",
    "    content = \"\\n\".join(content_lines)\n",
    "    return {\"ids\": articles_ids, \"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Function to calculate F1 beta score\n",
    "def f1_beta(pred, actual, beta=4):\n",
    "    TP, FP, FN = 0, 0, 0\n",
    "    for pred_list, actual_list in zip(pred, actual):\n",
    "        pred_set = set(pred_list)\n",
    "        actual_set = set(actual_list)\n",
    "        TP += len(pred_set & actual_set)\n",
    "        FP += len(pred_set - actual_set)\n",
    "        FN += len(actual_set - pred_set)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    if precision + recall > 0:\n",
    "        f1_beta_score = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)\n",
    "    else:\n",
    "        f1_beta_score = 0\n",
    "    score = dict()\n",
    "    score[\"recall\"] = recall\n",
    "    score[\"precision\"] = precision\n",
    "    score[\"f1_beta\"] = f1_beta_score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Load and process the question-answer dataset\n",
    "df = pd.read_json(\"/Users/nhotin/Documents/GitHub/LegalBizAI_project/test_set/id_cof/chunk_sz_fl_point/qasetfinal.json\")\n",
    "df = df[[\"question\", \"chunk_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Load all chunks\n",
    "filepath = \"/Users/nhotin/Documents/GitHub/LegalBizAI_project/test_set/id_cof/chunk_sz_fl_point/all_chunk_final.json\"\n",
    "with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_chunks = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Function to get retrieval ids for a question\n",
    "def retrieval_ids(question):\n",
    "    def preprocessing(promt):\n",
    "        question= promt.strip().lower()\n",
    "        question = re.sub(r'[^\\w\\s]', '', question)\n",
    "        words = question.split()\n",
    "        words = [word for word in words if word not in stop_words_vn]\n",
    "        return \" \".join(words)\n",
    "    top_chunk = retrieve(preprocessing(question), topk=3)\n",
    "    best_chunk_ids = getTopSimi(top_chunk)[\"ids\"]\n",
    "    return get_full_article(all_chunks, best_chunk_ids)[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.47810713343301964, 'precision': 0.3860566201224449, 'f1_beta': 0.4714940724692552}\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Apply retrieval_ids function and evaluate the model\n",
    "df[\"pred_ids\"] = df[\"question\"].apply(retrieval_ids)\n",
    "actual = df[\"chunk_ids\"].tolist()\n",
    "pred = df[\"pred_ids\"].to_list()\n",
    "print(f1_beta(pred, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>chunk_ids</th>\n",
       "      <th>pred_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thứ tự thanh toán khoản nợ của doanh nghiệp gi...</td>\n",
       "      <td>[1683, 1684, 1685, 1686, 1687, 1688, 1689, 169...</td>\n",
       "      <td>[1683, 1684, 1685, 1686, 1687, 1688, 1689, 169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Các khoản nợ của doanh nghiệp tư nhân giải thể...</td>\n",
       "      <td>[1683, 1684, 1685, 1686, 1687, 1688, 1689, 169...</td>\n",
       "      <td>[1683, 1684, 1685, 1686, 1687, 1688, 1689, 169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tình trạng đã phá sản của doanh nghiệp là gì?</td>\n",
       "      <td>[2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]</td>\n",
       "      <td>[2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hội đồng giải thể doanh nghiệp do Nhà nước nắm...</td>\n",
       "      <td>[2799, 2800, 2801, 2802, 2803, 2804, 2805, 280...</td>\n",
       "      <td>[2799, 2800, 2801, 2802, 2803, 2804, 2805, 280...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Doanh nghiệp do Nhà nước nắm giữ 100% vốn điều...</td>\n",
       "      <td>[2763, 2764, 2765, 2766, 2767, 2768, 2769, 277...</td>\n",
       "      <td>[2763, 2764, 2765, 2766, 2767, 2768, 2769, 277...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>Trường hợp nào sẽ tiến hành bầu dồn phiếu?</td>\n",
       "      <td>[1158, 1159, 1160, 1161, 1162, 1163, 1164, 116...</td>\n",
       "      <td>[1158, 1159, 1160, 1161, 1162, 1163, 1164, 116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>Vốn có quyền biểu quyết là gì?</td>\n",
       "      <td>[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
       "      <td>[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>Quyền được cung cấp thông tin của Ban kiểm soá...</td>\n",
       "      <td>[1414, 1415, 1416, 1417, 1418, 1419]</td>\n",
       "      <td>[1414, 1415, 1416, 1417, 1418, 1419]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>Điều kiện để công ty TNHH 2 thành viên trở lên...</td>\n",
       "      <td>[548]</td>\n",
       "      <td>[548]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>Tổng giám đốc công ty TNHH 2 thành viên trở lê...</td>\n",
       "      <td>[504, 505, 506, 507, 508, 509, 510, 511, 512, ...</td>\n",
       "      <td>[504, 505, 506, 507, 508, 509, 510, 511, 512, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2081 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "4     Thứ tự thanh toán khoản nợ của doanh nghiệp gi...   \n",
       "6     Các khoản nợ của doanh nghiệp tư nhân giải thể...   \n",
       "7         Tình trạng đã phá sản của doanh nghiệp là gì?   \n",
       "9     Hội đồng giải thể doanh nghiệp do Nhà nước nắm...   \n",
       "11    Doanh nghiệp do Nhà nước nắm giữ 100% vốn điều...   \n",
       "...                                                 ...   \n",
       "5547         Trường hợp nào sẽ tiến hành bầu dồn phiếu?   \n",
       "5551                     Vốn có quyền biểu quyết là gì?   \n",
       "5555  Quyền được cung cấp thông tin của Ban kiểm soá...   \n",
       "5559  Điều kiện để công ty TNHH 2 thành viên trở lên...   \n",
       "5560  Tổng giám đốc công ty TNHH 2 thành viên trở lê...   \n",
       "\n",
       "                                              chunk_ids  \\\n",
       "4     [1683, 1684, 1685, 1686, 1687, 1688, 1689, 169...   \n",
       "6     [1683, 1684, 1685, 1686, 1687, 1688, 1689, 169...   \n",
       "7      [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]   \n",
       "9     [2799, 2800, 2801, 2802, 2803, 2804, 2805, 280...   \n",
       "11    [2763, 2764, 2765, 2766, 2767, 2768, 2769, 277...   \n",
       "...                                                 ...   \n",
       "5547  [1158, 1159, 1160, 1161, 1162, 1163, 1164, 116...   \n",
       "5551  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...   \n",
       "5555               [1414, 1415, 1416, 1417, 1418, 1419]   \n",
       "5559                                              [548]   \n",
       "5560  [504, 505, 506, 507, 508, 509, 510, 511, 512, ...   \n",
       "\n",
       "                                               pred_ids  \n",
       "4     [1683, 1684, 1685, 1686, 1687, 1688, 1689, 169...  \n",
       "6     [1683, 1684, 1685, 1686, 1687, 1688, 1689, 169...  \n",
       "7      [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]  \n",
       "9     [2799, 2800, 2801, 2802, 2803, 2804, 2805, 280...  \n",
       "11    [2763, 2764, 2765, 2766, 2767, 2768, 2769, 277...  \n",
       "...                                                 ...  \n",
       "5547  [1158, 1159, 1160, 1161, 1162, 1163, 1164, 116...  \n",
       "5551  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...  \n",
       "5555               [1414, 1415, 1416, 1417, 1418, 1419]  \n",
       "5559                                              [548]  \n",
       "5560  [504, 505, 506, 507, 508, 509, 510, 511, 512, ...  \n",
       "\n",
       "[2081 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 13: Display the dataframe and compare predictions with actual chunk ids\n",
    "df\n",
    "df[df[\"chunk_ids\"] == df[\"pred_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k: 5, Recall: 0.6387545078722843, Precision: 0.4082298049356344, F1-beta: 0.6182189661129834\n",
      "Top-k: 10, Recall: 0.7219456416571378, Precision: 0.2900528666742056, F1-beta: 0.6638037008281573\n",
      "Top-k: 15, Recall: 0.7557216993579031, Precision: 0.22761785167405807, F1-beta: 0.6649679081231739\n",
      "Top-k: 20, Recall: 0.7801917494942388, Precision: 0.18732998800412254, F1-beta: 0.6577432153737173\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Experiment with different top-k values\n",
    "for topk in range(5, 21, 5):  \n",
    "    def retrieval_ids_experiment(question):\n",
    "        top_chunk = retrieve(question, topk=topk)\n",
    "        best_chunk_ids = getTopSimi(top_chunk)[\"ids\"]\n",
    "        return get_full_article(all_chunks, best_chunk_ids)[\"ids\"]\n",
    "\n",
    "    df[\"pred_ids\"] = df[\"question\"].apply(retrieval_ids_experiment)\n",
    "    actual = df[\"chunk_ids\"].tolist()\n",
    "    pred = df[\"pred_ids\"].to_list()\n",
    "    scores = f1_beta(pred, actual)\n",
    "    print(f\"Top-k: {topk}, Recall: {scores['recall']}, Precision: {scores['precision']}, F1-beta: {scores['f1_beta']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
